{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WISO100303 / Johannes Schmidt & Peter Regner\n",
    "\n",
    "# **An introduction to scientific programming**\n",
    "\n",
    "<br> <br> <br> <br><br> <br> <br> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNTRIES = 'Austria', 'Germany', 'Switzerland', 'Italy', 'Spain', 'Sweden', 'United Kingdom'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this for larger plots:\n",
    "#matplotlib.rc('figure', figsize=(15, 10))\n",
    "matplotlib.rc('figure', figsize=(10, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "We use a rather extensive data set during this class. Below, there is automatic download code for that data. After each restart of your notebook, [Datalore will download the file again](https://datalore-forum.jetbrains.com/t/how-to-sync-or-copy-files-without-the-web-interface/787/8) if the Datalore kernel is used, which takes time. If you want to spare that time, we therefore recommend to manually upload the data. To do so, please:\n",
    "- Download the following files from boku box listed in the code cell below\n",
    "- Click on the paperclick symbol on the left\n",
    "- Click on the upload button (at the bottom) and choose to upload the file you just downloaded\n",
    "- Wait until the upload is finished\n",
    "\n",
    "Note: unfortunately there is a [bug in Datalore](https://datalore-forum.jetbrains.com/t/uploading-from-url-progress-message-does-not-show-completion/856), when using _Upload from URL_. It might work too, but at least the progress message seems to be wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_era5_temperature():\n",
    "    import os\n",
    "    import cdsapi\n",
    "\n",
    "    c = cdsapi.Client()\n",
    "\n",
    "    filename = 'temperatures_era5.nc'\n",
    "    north, west, south, east = 70.,-13.5, 35.5, 24.5\n",
    "\n",
    "    c.retrieve(\n",
    "        'reanalysis-era5-land',\n",
    "        {\n",
    "            'format': 'netcdf',\n",
    "            'variable': '2m_temperature',\n",
    "            'area': [\n",
    "                north, west, south, east\n",
    "            ],\n",
    "            'grid': [0.5, 0.5],  # grid in 0.5deg steps in longitude/latitude\n",
    "            'day': [f\"{day:02d}\" for day in range(1, 32)],\n",
    "            'time': [f\"{hour:02d}:00\" for hour in range(24)],\n",
    "            'month': [f\"{month:02d}\" for month in range(1, 13)],\n",
    "            'year': [str(year) for year in range(2015, 2021)],\n",
    "        },\n",
    "        f\"{filename}.part\")\n",
    "\n",
    "    # this prevents you from accidentally using broken files:\n",
    "    os.rename(f\"{filename}.part\", filename)\n",
    "\n",
    "# download_era5_temperature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# workaround: Datalore does not allow to publish attached files, so we have to download it.\n",
    "def download_attached_files():\n",
    "    import urllib\n",
    "    import os.path\n",
    "    fnames = {\n",
    "              'entsoe-demand-shortened.pickle': 'https://bokubox.boku.ac.at/index.php/get/4bbdac7c2872bd8cefd4fb6a4267a879/entsoe-demand-shortened.pickle',\n",
    "              'temperatures_era5.nc': 'https://bokubox.boku.ac.at/index.php/get/181272eaf961fda5bd240fa70644e400/temperatures_era5.nc',\n",
    "              #'countries.geojson': 'https://bokubox.boku.ac.at/index.php/get/de2d9a661f31c67f961a7157fdb64781/countries.geojson',\n",
    "              'country_points.csv': 'https://bokubox.boku.ac.at/index.php/get/9c8f2d8138fa659887a0592f0132f56f/country_points.csv',\n",
    "    }\n",
    "    for fname, url in fnames.items():\n",
    "        if not os.path.exists(fname):\n",
    "            urllib.request.urlretrieve(url, filename=fname)\n",
    "\n",
    "download_attached_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hourly_country_data(data, country):\n",
    "    ret_data = data[data[\"AreaName\"] == country].interpolate() # data may contain NAs, therefore inteprolate\n",
    "    ret_data = ret_data.resample(\"1h\").mean().interpolate() # not all hours may be  complete \n",
    "                                                            # (i.e. some last 15 minutes are lacking, therefore another inpolation here)\n",
    "\n",
    "    return ret_data\n",
    "\n",
    "power_demand = pd.read_pickle(\"entsoe-demand-shortened.pickle\")\n",
    "\n",
    "power_demand = power_demand.loc[\"2015-01-01\":\"2019-12-31\"]\n",
    "power_demand_at_hourly = get_hourly_country_data(power_demand, \"Austria\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temperature data\n",
    "\n",
    "ERA5 data is provided as NetCDF file. The library `xarray` comes in very handy to load such files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures_dataset = xr.open_dataset('temperatures_era5.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `open_dataset()` does not load all data into RAM. So it is very fast. No values are read from disk yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures = temperatures_dataset.t2m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures.isel(time=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures.sel(time='2020-03-29 17:00').values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh there are NaN values? How many of them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size = temperatures.sizes['time'] * temperatures.sizes['latitude'] * temperatures.sizes['longitude']\n",
    "float(np.isnan(temperatures).sum() / total_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh 55% of missing values.. That's not good! What could that be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(~np.isnan(temperatures)).prod(dim='time').plot.imshow(cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** We downloaded the product `'reanalysis-era5-land'`, there is also `'era5-single-levels'` which contains data also for locations in the sea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Plot the mean temperature in C° for each location!\n",
    "\n",
    "- Which ways are there to plot the temperature?\n",
    "- Can you think of at least two different plots?\n",
    "- Can you use `xarray` directly for plotting?\n",
    "- Keep an eye on the axes labels! Is this done automatically? If so, how does this work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temperature seems not to be in °C..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures = temperatures - 273.15\n",
    "temperatures.name = 'Temperature [C°]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures.mean(dim='time').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures.mean(dim=['latitude', 'longitude']).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Plot the temperatures at our location.\n",
    "\n",
    "**Instructions:**\n",
    "- first use the manual way and try to find the nearest coordinates and then use the `.sel()` method, note that we are using a 0.5° grid\n",
    "- now directly pass the coordinates and use the parameter `method='nearest'` to get the temperature of the nearest grid point\n",
    "\n",
    "What was the temperature on the 13th of March 2020 at 14:00?\n",
    "\n",
    "**Note:** Vienna is approximately at lognitude=16, latitude=48 - not the other way around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "you_are_here =  np.array([16.357709, 48.232303])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "you_ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures.sel(longitude=round(you_are_here[0] * 2)/2, latitude=round(you_are_here[1] * 2)/2).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures.sel(longitude=you_are_here[0], latitude=you_are_here[1], method='nearest').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures.sel(longitude=you_are_here[0], latitude=you_are_here[1], time='2020-03-13 14:00', method='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick random grid points to calculate the mean\n",
    "\n",
    "As a next step, we want to calculate the mean temperature for each country."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll pick just some random samples from the grid for each country, to make computation of the mean faster. The coordinates are already prepared as CSV file, which has been generated using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_country_points(longitude, latitude, grid_points_per_country=200):\n",
    "    \"\"\"Pick random points for each country from the grid with axis ``longitude`` and ``latitude``.\n",
    "    ``size`` is the number of points ot be picked for \n",
    "    \n",
    "    Returns a dataframe with two columns per country (longitude & latitude)\n",
    "    and ``grid_points_per_country`` numbers of rows.\n",
    "    \n",
    "    Note: GeoJSON always uses WGS84:\n",
    "    https://tools.ietf.org/html/rfc7946\n",
    "    \n",
    "    \"\"\"\n",
    "    # local import to avoid dependency\n",
    "    import geopandas\n",
    "    from shapely.geometry import Point\n",
    "    \n",
    "    longitudes, latitudes = np.meshgrid(longitude, latitude)\n",
    "    \n",
    "    longitudes = longitudes.flatten()\n",
    "    latitudes = latitudes.flatten()\n",
    "    \n",
    "    grid_points = geopandas.GeoSeries(geopandas.points_from_xy(longitudes.flatten(),\n",
    "                                                           latitudes.flatten()))\n",
    "    \n",
    "    # XXX fix me, correct path!\n",
    "    country_borders = geopandas.read_file('countries.geojson')\n",
    "\n",
    "    chosen_gridpoints = pd.DataFrame()\n",
    "\n",
    "    for country in COUNTRIES:\n",
    "        print(f\"Picking grid points for {country}...\")\n",
    "        is_country = country_borders.ADMIN == country\n",
    "\n",
    "        country_border = country_borders[is_country].geometry.iloc[0]\n",
    "\n",
    "        is_in_country = grid_points.within(country_border)\n",
    "\n",
    "        number_of_points = is_in_country.sum()\n",
    "        \n",
    "        # make things reproducible!\n",
    "        np.random.seed(42)\n",
    "        \n",
    "        idcs = np.random.randint(number_of_points, size=grid_points_per_country)\n",
    "\n",
    "        chosen_gridpoints[f'{country}_longitude'] = longitudes[is_in_country][idcs]\n",
    "        chosen_gridpoints[f'{country}_latitude'] = latitudes[is_in_country][idcs]\n",
    "        \n",
    "    return chosen_gridpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to recreate the `country_points.csv` one needs to install `geopandas` and download a `GeoJSON` file (23MB) which contains the country borders. On windows there might be no `wget` command, use `requests.get()` instead to download the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install --yes geopandas\n",
    "# !wget -O ../data/countries.geojson https://raw.githubusercontent.com/datasets/geo-countries/master/data/countries.geojson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines create the `country_points.csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# country_points = choose_country_points(temperatures.longitude, temperatures.latitude)\n",
    "# country_points.to_csv('../data/country_points.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But since it is already prepared, let's just load it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_points = pd.read_csv('country_points.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(country_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plote some of these points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(country_points['Austria_longitude'], country_points['Austria_latitude'], 'o')\n",
    "plt.xlabel('Longitude [deg]')\n",
    "plt.ylabel('Latitude [deg]');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(country_points['Germany_longitude'], country_points['Germany_latitude'], 'o')\n",
    "plt.xlabel('Longitude [deg]')\n",
    "plt.ylabel('Latitude [deg]');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate mean temperature for each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = 'Austria'\n",
    "country_temperature = temperatures.sel(\n",
    "        longitude=xr.DataArray(country_points['Austria_longitude'], dims='points'),\n",
    "        latitude=xr.DataArray(country_points['Austria_latitude'], dims='points'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_country_temperature(country):\n",
    "    country_temperature = temperatures.sel(\n",
    "        longitude=xr.DataArray(country_points[f'{country}_longitude'], dims='points'),\n",
    "        latitude=xr.DataArray(country_points[f'{country}_latitude'], dims='points')).mean(dim='points')\n",
    "    return country_temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_at = calc_country_temperature('Austria')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_at.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x# XXX this does not seem to be correct... 2019 had a lower electricity consumption than 2018, so we assume it was very warm.\n",
    "# But this plot is shifted, there is no 2021 data in there... no time for that! giving up.\n",
    "temperature_at.resample(time='Y').mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Who likes to have it warm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(temperature_at.sel(time=power_demand_at_hourly.index),\n",
    "         power_demand_at_hourly, 'o')\n",
    "plt.xlabel('Temperature [°C]')\n",
    "plt.ylabel('Load [MW]');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the U shaped relation between load and temperature, but there is a lot of variation in there. Could we reduce this somehow?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idcs = (power_demand_at_hourly.index.weekday == 2) & (power_demand_at_hourly.index.hour == 9)\n",
    "idcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(temperature_at.sel(time=power_demand_at_hourly.index[idcs]),\n",
    "         power_demand_at_hourly[idcs], 'o')\n",
    "plt.ylim(6_000, 11_000)\n",
    "plt.xlabel('Temperature [°C]')\n",
    "plt.ylabel('Load [MW]')\n",
    "plt.title(\"Load vs Temperature (Wednesdays 9:00am)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import median_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_demand_at_hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_temperature = pd.DataFrame()\n",
    "power_temperature['TotalLoadValue'] = power_demand_at_hourly.TotalLoadValue[idcs]\n",
    "power_temperature['Temperature'] = temperature_at.interp(time=power_demand_at_hourly.index[idcs])\n",
    "\n",
    "power_temperature = power_temperature.sort_values('Temperature')\n",
    "\n",
    "#plt.plot(power_temperature.Temperature,\n",
    "#         power_temperature.TotalLoadValue, '-')\n",
    "\n",
    "plt.plot(power_temperature.Temperature,\n",
    "         median_filter(power_temperature.TotalLoadValue,\n",
    "                                                 mode='nearest',\n",
    "                                                 size=30),\n",
    "         '-')\n",
    "\n",
    "plt.ylim(6_000, 11_000)\n",
    "plt.xlabel('Temperature [°C]')\n",
    "plt.ylabel('Load [MW]')\n",
    "plt.title(\"Load vs Temperature (Wednesdays 9:00am)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `median_filter()` will replace each value by the median of it's surroundings of size `size`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_filter(np.array([1., 1., 1., 1., 5., 1., 1.]), size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_filter(np.array([1., 1., 1., 1., 5., 5., 1.]), size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for country in COUNTRIES:\n",
    "#for country in ('Austria', 'Germany', 'Switzerland'):\n",
    "#for country in ('Spain', 'Italy'):\n",
    "    power_demand_country = power_demand[power_demand.AreaName == country]\n",
    "\n",
    "    country_temperature = calc_country_temperature(country)\n",
    "\n",
    "    # select observations from Wednesdays 9:00am\n",
    "    idcs = (power_demand_country.index.weekday == 2) & (power_demand_country.index.hour == 9)\n",
    "\n",
    "    power_temperature = pd.DataFrame()\n",
    "\n",
    "    power_temperature['TotalLoadValue'] = power_demand_country.TotalLoadValue[idcs]\n",
    "    power_temperature['Temperature'] = country_temperature.interp(time=power_demand_country.index[idcs])\n",
    "    power_temperature = power_temperature.sort_values('Temperature')\n",
    "\n",
    "    normalized_load = power_temperature.TotalLoadValue / power_temperature.TotalLoadValue.mean()\n",
    "    normalized_load_filtered =  median_filter(normalized_load, mode='nearest', size=30)\n",
    "    \n",
    "    lines, = plt.plot(power_temperature.Temperature, normalized_load_filtered, '-', label=country)\n",
    "    \n",
    "    #if country == 'United Kingdom':\n",
    "    #    plt.plot(power_temperature.Temperature, normalized_load, 'o-',\n",
    "    #             linewidth=0.5, markersize=2, alpha=0.4,\n",
    "    #             color=lines.get_color(),\n",
    "    #             label=f\"{country} (unfiltered)\")\n",
    "\n",
    "\n",
    "plt.xlabel('Temperature [°C]')\n",
    "plt.ylabel('Load relative to mean load')\n",
    "plt.legend();"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "generative_ai_disabled": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python",
   "language": "python3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
