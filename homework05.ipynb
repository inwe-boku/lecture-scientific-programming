{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 - Terminology\n",
    "\n",
    "Describe the following terms with your own words:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Shape of a numpy array:***\n",
    "\n",
    "***Elementwise operation:*** \n",
    "\n",
    "***Name at least 4 packages used in the python scientific ecosystem and explain when they are helpful:***\n",
    "\n",
    "***How many dimensions do the following numpy arrays have?*** (Hint: use the command shape to confirm your answers!)\n",
    "-  `np.array([1])`\n",
    "-  `np.array([[1, 2, 3], [1, 2, 3]])`\n",
    "-  `np.array([1, 2, 3, 1, 2, 3])`\n",
    "-  `np.array([[1]])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93a8415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # # YOUR SOLUTION GOES HERE # # # # #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 - Wind speeds\n",
    "\n",
    "Given is a numpy array `wind_speeds` which contains hourly wind speed time series along the latitude 62.721° in m/s. The columns are different (equidistant) positions ranging from longitude -172.714° to -160.46388°. The rows are different hourly time stamps starting at 2012-03-01 (in total three days).\n",
    "\n",
    "- Determine the shape of the array and check if the results are plausible, i.e. do the dimensions of the array correspond to the number of data points expected?\n",
    "- Calculate the mean wind speed over all locations (store it in variable `wind_speeds_mean`) and at the longitude -160.46388° (store it in `wind_speeds_lon160_mean`)\n",
    "- Plot the wind speeds across the given longitudes at 2012-03-01 12:00 (assume 00:00 is the first row)\n",
    "- Plot the time series at longitude -160.46388° (use a second figure)\n",
    "\n",
    "Don't forget to label all axes!\n",
    "\n",
    "(You do not need to take care about the values on the axis.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 8)  # you can change this to adjust the figure size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# donwload the data\n",
    "import urllib\n",
    "import os.path\n",
    "fname = 'windspeeds.csv'\n",
    "if not os.path.exists(fname):\n",
    "    URI = 'https://files.boku.ac.at/filr/public-link/file-download/0d7483c99572915f0195892102c26e01/18661/2534960446703962903/' + fname\n",
    "    urllib.request.urlretrieve(URI, filename=fname)\n",
    "\n",
    "wind_speeds = np.genfromtxt(fname, delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_speeds[:5, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b8e23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # # YOUR SOLUTION GOES HERE # # # # #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24198c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # # YOUR SOLUTION GOES HERE # # # # #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # # RUN THIS CELL TO CHECK YOUR RESULTS # # # # # \n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "import os.path\n",
    "if not os.path.exists('check.py'):\n",
    "    urlretrieve('https://raw.githubusercontent.com/inwe-boku/lecture-scientific-programming/refs/heads/main/check.py', filename='check.py')\n",
    "from check import check_solution\n",
    "check_solution([\n",
    "    (\"mean_windpower_mw\", 0.38),\n",
    "    (\"min_windpower_mw\", 0.00),\n",
    "    (\"max_windpower_mw\", 1.53),\n",
    "    (\"mean_windpower_longitude_172\", 0.54),\n",
    "    (\"mean_windpower_longitude_160\", 0.04)\n",
    "], globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4 - Covid-19 cases\n",
    "\n",
    "The CSV file `covid19_austria.csv` contains on Covid-19 cases in Austria in 3 columns in this order: date, cumulative confirmed cases and cumulative reported deaths. Use the function `np.genfromtxt()` with the parameter `delimiter=','` to read the CSV file and load it to a numpy array.\n",
    "\n",
    "The first row contains the header of the CSV file (the titles of the columns). It is not supposed to be used. Also use a slicing operation to get rid of the first column before doing the steps below. The first column contains the dates, which are not parsed correctly by `np.genfromtxt()`, but since the CSV file is sorted, we can just assume the numpy array contains a value for each day since the start of the pandemic in Austria.\n",
    "\n",
    "- Plot the cumulative confirmed cases during the last 150 days. You can compare your result to [this plot](https://ourworldindata.org/explorers/coronavirus-data-explorer?zoomToSelection=true&time=2021-10-15..latest&facet=none&hideControls=true&Metric=Confirmed+cases&Interval=Cumulative&Relative+to+Population=false&Color+by+test+positivity=false&country=~AUT).\n",
    "\n",
    "- Plot the case fatality rate in percent, by dividing the number of total deaths by the number of total cases. You can compare your result to [this plot](https://ourworldindata.org/explorers/coronavirus-data-explorer?zoomToSelection=true&time=2020-03-14..latest&facet=none&pickerSort=asc&pickerMetric=location&hideControls=true&Metric=Case+fatality+rate&Interval=Cumulative&Relative+to+Population=false&Color+by+test+positivity=true&country=~AUT).\n",
    "\n",
    "- Use the function `np.diff()` on the second column (cases) to get the daily cases. (find in the documentation why this is the right way to do it). Then use the function `np.argmax()` to find how many days ago (relative to the end of the data set) the maximum of daily cases was reported and store the result in the variable `maximum_before_days`.\n",
    "\n",
    "\n",
    "Note that the second plot has to be interpreted with a grain of salt as the number of tests vary a lot. Therefore, the number of true deaths and true cases is not known and may differ a lot from the reported values. See [here](http://ourworldindata.org/mortality-risk-covid) for a more detailed analysis of this issue.\n",
    "\n",
    "This exercise has been created in 2022. As of 2024 the number of performed Covid-19 tests is much lower, therefore the number of positive tests is not comparable. The [waste water monitoring](https://abwassermonitoring.at/dashboard/) indicates that there is still a very high number of new Covid-19 infections:\n",
    "\n",
    "![Screenshot waste water monitoring](images/screenshot-waste-water-monitoring.png)\n",
    "\n",
    "(This exercise uses numpy only and should mostly help to understand the concepts of numpy. During the next lectures, we will use pandas instead, which makes the same task a bit easier.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code snipped was used to produce the CSV file used in this exercise. It downloads data from AGES and preprocesses them\n",
    "# The result is already attached to the notbeook or can be downloaded from files.boku.ac.at directly (see code below).\n",
    "#\n",
    "# This means that you do not need to run the commented out code lines in this cell, because we did so already\n",
    "# for you. If you re-download the data from AGES, you might end up with slightly different results.\n",
    "\n",
    "# !wget --no-check-certificate --cipher 'DEFAULT:!DH' https://covid19-dashboard.ages.at/data/data.zip\n",
    "# !unzip data.zip\n",
    "# import pandas as pd\n",
    "# data = pd.read_csv(\"CovidFaelle_Timeline.csv\", delimiter=';', parse_dates=['Time'], dayfirst=True)\n",
    "# covid_austria = data[data['Bundesland'] == 'Österreich'].set_index('Time').sort_index()\n",
    "# new_data = pd.DataFrame({\n",
    "#    'Cases_total': covid_austria.AnzahlFaelleSum,\n",
    "#    'Deaths_total': covid_austria.AnzahlTotSum}\n",
    "# )\n",
    "# new_data.to_csv('covid19_austria.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# donwload the data\n",
    "import urllib\n",
    "import os.path\n",
    "\n",
    "fname = 'covid19_austria.csv'\n",
    "if not os.path.exists(fname):\n",
    "    URI = 'https://files.boku.ac.at/filr/public-link/file-download/0d7483c99572915f01958920c2806cf5/18657/8759111527431771580/covid19_austria.csv'\n",
    "    urllib.request.urlretrieve(URI, filename=fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_covid_cases_austria():\n",
    "    raw_data_dataframe = pd.read_csv('covid19_austria.csv', delimiter=',', dtype={'Cases_total': int, 'Deaths_total': int})\n",
    "    # return a numpy array, because pandas has not been introduced in the lecture yet\n",
    "    return raw_data_dataframe.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18b5a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # # YOUR SOLUTION GOES HERE # # # # #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023ee505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # # YOUR SOLUTION GOES HERE # # # # #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6 - Implement np.diff (optional bonus exercise)\n",
    "\n",
    "Re-implement the function [`np.diff()`](https://numpy.org/doc/stable/reference/generated/numpy.diff.html). Name the new function `my_diff`. It should take a one dimensional numpy array `a` as input and calculate the consecutive differences between the elements, i.e. the difference of the second element and the first element, the difference of the third element and the second element etc. You can ignore all optional parameters of `np.diff()`.\n",
    "\n",
    "- What is the length of the resulting array?\n",
    "- Can you see the relation to the derivative of a function?\n",
    "- Can you find a numpy function which does the reverse operation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13253c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # # YOUR SOLUTION GOES HERE # # # # #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # # RUN THIS CELL TO CHECK YOUR RESULTS # # # # # \n",
    "\n",
    "import numpy as np\n",
    "from urllib.request import urlretrieve\n",
    "import os.path\n",
    "if not os.path.exists('check.py'):\n",
    "    urlretrieve('https://raw.githubusercontent.com/inwe-boku/lecture-scientific-programming/refs/heads/main/check.py', filename='check.py')\n",
    "from check import check_solution\n",
    "test_values = np.arange(3), np.zeros(10), np.array([1., 2.5, 5.]), np.array([])\n",
    "check_solution([\n",
    "    (f\"my_diff(test_values[{i}])\", np.diff(test_values[i]), None, np.testing.assert_allclose, 'check')\n",
    "    for i in range(len(test_values))\n",
    "], globals())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "generative_ai_disabled": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python",
   "language": "python3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
