{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WISO100303 / Johannes Schmidt & Peter Regner\n",
    "\n",
    "# **An introduction to scientific programming**\n",
    "\n",
    "<br> <br> <br> <br><br> <br> <br> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data\n",
    "We use a rather extensive data set during this class. Below, there is automatic download code for that data. The download needs to be done only once, since Datalore stores the file in the Notebook files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# donwload the data\n",
    "def download_attached_files():\n",
    "    import urllib\n",
    "    import os.path\n",
    "    fnames = {\n",
    "              'entsoe-demand-shortened.pickle': 'https://files.boku.ac.at/filr/public-link/file-download/0d7483c9959b20360196809f11ff2d67/18707/-4160977441044749444/entsoe-demand-shortened.pickle'\n",
    "    }\n",
    "    for fname, url in fnames.items():\n",
    "        if not os.path.exists(fname):\n",
    "            print(f'Downloading: {url}')\n",
    "            urllib.request.urlretrieve(url, filename=fname)\n",
    "            print(f'Download finished!')\n",
    "        else:\n",
    "            print(\"File already exists, not downloading again.\")\n",
    "\n",
    "download_attached_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It takes about 3min to donwload the ENTSO-E data from Google Colab. Use the\n",
    "# code below to cache the data on your own Google Drive. You will need grant\n",
    "# permissions to \"Google Drive for Desktop\" for some reason to make it work.\n",
    "#\n",
    "# from google.colab import drive\n",
    "# import shutil\n",
    "# drive.mount('/content/drive')\n",
    "# if os.path.exists('/content/drive/MyDrive' + fname):\n",
    "#    if not os.path.exists(fname):\n",
    "#        shutil.copy('/content/drive/MyDrive' + fname, '/content/')\n",
    "# else:\n",
    "#    if not os.path.exists(fname):\n",
    "#        urllib.request.urlretrieve(url, filename=fname)\n",
    "#    shutil.copy('/content/' + fname, '/content/drive/MyDrive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "\n",
    "Today, we work with the `Pandas` library. `Pandas` is a library  that allows to handle multi-type data frames, i.e. unlike in numpy, which allows only one data type per array, in a `Pandas` dataframe each column can be a different data type. Think of `Pandas` as providing the functionality of Excel to you in Python: you can sort data, aggregate data, do calculations on data, etc. The advantage:\n",
    "- You can automatize your tasks\n",
    "- You can reproduce your analysis\n",
    "- You can separate data and code\n",
    "\n",
    "`Pandas` is built on top of numpy, so many operations you know from numpy, may work as well in `Pandas`.\n",
    "\n",
    "`Pandas` dataframes have column names, which can be used to acces them (see below). They also have an index for rows, such as e.g. date and time of a sample in the table. During class, we will learn to handle both column names as well as the index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data example: which simple patterns can we identify in electricity demand?\n",
    "\n",
    "Today we want to use the `Pandas` library to study which temporal patterns we can find in Austrian electricity demand. When do people use more electricity? When do they use less electricity?\n",
    "\n",
    "For that purpose we use data provided by ENTSO-e, that is the \"European association for the cooperation of transmission system operators\". They provide hourly data for most European countries, informing about the \"load\" on the network. The load indicates how much electricity was produced - and consumed. We will look into the dataset which spans from late 2014 to today and aim at understanding consumption patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "\n",
    "We load data from the file we just downloaded. It contains load measured on grids in the whole of Europe, provided by entso-e. You can download the raw CSV files from the entso-e website directly, but we have done so for you, as the download takes substantial time. The pickle file, which is hosted on a bokubox, contains all relevant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_demand = pd.read_pickle(\"entsoe-demand-shortened.pickle\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Pickle is [not a good file format for data exchange](https://nedbatchelder.com/blog/202006/pickles_nine_flaws.html). There are security dangers and possible compatibility issues. Unfortunately all other formats (except pickle, npz and cvs) require to install additional packages on Datalore. To avoid the hassle, we used pickle despite its risks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's in there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_demand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot of information... let's get an overview! Which columns are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_demand.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pandas, rows can also have names. They are called the index of the pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_demand.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acessing data\n",
    "\n",
    "The `dataframe.columns` attribute tells us, which columns are available in our table. To access a column, you can use `dataframe_name[\"Column name\"]`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_demand[\"AreaName\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which areas are there? The command `unique()` will give you a listing of unique entries in that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_demand[\"AreaName\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do the abbreviations mean? Do you think Austria is there? But what if the list was very long and we do not want to check manually if we can find Austria in the list of unique countries?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a comparison and `np.sum` to find out! Please observe that a boolean value is assumed to be 1 if it is `True`, and 0 otehrwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(power_demand[\"AreaName\"] == \"AT CTY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does that answer tell us?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also access rows of the dataframe by using the method `.loc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_demand.loc['2015-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_demand.loc['2015-01-01 00:00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_demand.loc['2015-01-01':'2015-02-02']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to, we can also access a row or a column by its numerical index (similar to numpy). For that purpose, we have to use `.iloc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_demand.iloc[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get Austrian data! We can filter rows by the values of a column using `dataframe_name[dataframe_name[\"column_name\"]== criterium]`. This is similar to how we filtered numpy arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_country(load, country):\n",
    "    country_load = load[load[\"AreaName\"] == country]\n",
    "    return country_load\n",
    "\n",
    "\n",
    "power_demand_at = filter_country(power_demand, \"AT CTY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_demand_at"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Let's do some summary statistics. Calculate mean, standard deviation, min, max and the 25%, 50% and 75% quantile of the distribution of the Austrian data. Hint: There may be a single pandas function that does it for you...\n",
    "\n",
    "In a second step, do the same for Germany. Does the * 10 rule hold? (everything in Germany is ten times as big as in Austria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12434452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # # YOUR SOLUTION GOES HERE # # # # #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:#555;border-top:1px solid #999;text-align:right;padding:4px;\">End of exercise</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting pandas data + some additional index information\n",
    "\n",
    "The nice thing about pandas is, that one can simply use `.plot()` on the dataframe and pandas will do an appropriate plot of the underlying data. Now it is important to understand the index better - because the x-axis will be the index! If no index is given, pandas automatically creates one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'data1': [2, 1, 7],\n",
    "        'data2': [3, 4, 5]}\n",
    "\n",
    "# Creating a new dataframe without index. Pandas will automatically create an index.\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating a new dataframe with integer index\n",
    "df = pd.DataFrame(data, index=[1, 3, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new dataframe with string index.\n",
    "df = pd.DataFrame(data, index=[\"house\", \"car\", \"pet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot the Austrian data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(data, xlabel=\"Time\"):\n",
    "    data[\"TotalLoadValue\"].plot()\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(\"Electricity load (MW)\")\n",
    "\n",
    "\n",
    "plot_data(power_demand_at)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hm... there may be outliers. But how complete is the Austrian data?\n",
    "\n",
    "Observe: we use f-strings here. It is a very convenient way of merging strings with variables. More at the end of the lecture!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data_completeness(data):\n",
    "    number_of_nas = np.sum(pd.isna(data[\"TotalLoadValue\"]))\n",
    "    number_of_0s = np.sum(data[\"TotalLoadValue\"] == 0)\n",
    "\n",
    "    print(f'The data contains {number_of_nas} NAs and {number_of_0s} zeros')\n",
    "\n",
    "\n",
    "check_data_completeness(power_demand_at)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "What is the time resolution of the dataset? There are several ways of finding it, try to find at least two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7df30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # # YOUR SOLUTION GOES HERE # # # # #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:#555;border-top:1px solid #999;text-align:right;padding:4px;\">End of exercise</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data aggregation \n",
    "\n",
    "Let's aggregate the data to hourly. The `resample()` method allows us to do so (`1h` implies you aggregate to a resolution of one hour, check the documentation to see which other resolutions are available). Please observe that you have to use some method which is able to actually aggregate data to a different temporal resolution, such as `mean`, `max`, `min` or `sum`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_demand_at_hourly = power_demand_at.resample('1h').mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_demand_at"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are non numeric columns in the dataframe! To fix the warning, we add `numeric_only = true` to the call of the `mean` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_demand_at_hourly = power_demand_at.resample('1h').mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_demand_at_hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_data(power_demand_at_hourly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's look into the data more closely and find some regularities..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_demand_at_yearly = power_demand_at_hourly.resample('1y').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_demand_at_yearly.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(power_demand_at_yearly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time indexing\n",
    "\n",
    "Hm... 2014 and 2025 are incomplete. We should select the correct period therefore. This can be done by working on the time index of the dataframe, using `dataframe_name.loc` plus a date range in the brackets, i.e. `dataframe_name.loc['start-date':'end-date']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_demand_at_yearly.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_demand_at_yearly_full_years = power_demand_at_yearly.loc['2015-01-01':'2024-12-31']\n",
    "\n",
    "plot_data(power_demand_at_yearly_full_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_demand_at_yearly_full_years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot it relative to 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_demand_at_yearly_2015 = power_demand_at_yearly_full_years.loc['2015-12-31 00:00:00']\n",
    "power_demand_at_yearly_full_years_relative = 100 * power_demand_at_yearly_full_years / power_demand_at_yearly_2015\n",
    "power_demand_at_yearly_full_years_relative.plot()\n",
    "\n",
    "plt.ylabel('Relative to 2015 (%)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_demand_at_yearly_full_years_relative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hm... hard to tell if there is a trend. Time-series too short. Let's neglect it for the moment. Is there monhtly seasonality?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_demand_at_monthly = power_demand_at_hourly.resample('1M').mean()\n",
    "power_demand_at_monthly = power_demand_at_monthly.loc['2015-01-01':'2024-12-31']\n",
    "\n",
    "plot_data(power_demand_at_monthly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hm... seems to be seasonal, right?\n",
    "\n",
    "To understand it better, we could simply take the monthly average..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_demand_at_monthly_mean = power_demand_at.groupby(\n",
    "    power_demand_at.index.month).mean(numeric_only=True)\n",
    "\n",
    "plot_data(power_demand_at_monthly_mean, \"Month of Year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happend here? First, `power_demand_at.index.month` simply returns the month of a time index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_demand_at.index.month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With group_by we can calculate a function on subgroups of the original data. In our case, we calculate the `mean` for all values which belong to the same group, i.e. same month. Another example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'data1': [2, 1, 7, 3, 3, 22, 2, 1, 44],\n",
    "        'data2': [3, 4, 5, 3, 4, 4, 2, 2, 2]}\n",
    "\n",
    "# Creates pandas DataFrame.\n",
    "df = pd.DataFrame(data, index=[1, 1, 1, 1, 2, 3, 3, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(df.index).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"data1\"]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "There are at least two other time scales over which data shows seasonality. Can you find them and plot them? Hint: power_demand_at_hourly.index.weekday may be very useful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f1da54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # # YOUR SOLUTION GOES HERE # # # # #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:#555;border-top:1px solid #999;text-align:right;padding:4px;\">End of exercise</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A small detour: F-Strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During class, we have used `f-strings`. These are useful to come up with formatted strings that contain a mixture of expressions and strings. The syntax is `f''`. If one wants to output a variable, the curley brackets are used `{}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 1\n",
    "f'x is {x}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f'33*22={33*22}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even do additional formatting such as rounding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "f'Pi rounded to two digits is {np.pi:.2f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f'Pi rounded two 0 digits is {np.pi:.0f}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Caution!** This will work: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f'Power demand in Austria is {round(power_demand_at_yearly_full_years[\"TotalLoadValue\"].loc[\"2015-12-31 00:00:00\"])}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will also work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"Power demand in Austria is {round(power_demand_at_yearly_full_years['TotalLoadValue'].loc['2015-12-31 00:00:00'])}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this won't: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"Power demand in Austria is {round(power_demand_at_yearly_full_years[\"TotalLoadValue\"].loc[\"2015-12-31 00:00:00\"])}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
